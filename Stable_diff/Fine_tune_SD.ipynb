{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install diffusers transformers accelerate safetensors opencv-python\n",
        "# !pip install --upgrade diffusers transformers accelerate"
      ],
      "metadata": {
        "id": "Z89iTDh1nNCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnHVhPSCm7CR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLControlNetPipeline,ControlNetModel,AutoencoderKL\n",
        "from diffusers.utils import load_image\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Control Net + stable diffusion + refiner"
      ],
      "metadata": {
        "id": "7mCu6TahnIBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your ControlNet condition image (e.g., edge map or sketch)\n",
        "def load_canny_image(path):\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.Canny(image, 100, 200) #Applies Canny edge detection (highlighting edges as white lines on black)\n",
        "    image = Image.fromarray(image)\n",
        "    image = image.convert(\"RGB\").resize((768, 768))\n",
        "    return image\n",
        "\n",
        "# Step 1: Load ControlNet model (e.g., canny edges)\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"diffusers/controlnet-canny-sdxl-1.0\", torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Step 2: Load SDXL base pipeline with ControlNet\n",
        "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        ")\n",
        "\n",
        "\n",
        "# # Step 3: Load SDXL Refiner\n",
        "# refiner = StableDiffusionXLRefinerPipeline.from_pretrained(\n",
        "#     \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "#     torch_dtype=torch.float16,\n",
        "#     variant=\"fp16\",\n",
        "#     use_safetensors=True,\n",
        "# )\n",
        "\n",
        "\n",
        "# Step 4: Load your sketch/condition image\n",
        "control_image = load_canny_image(\"final_asteria.png\")\n",
        "\n",
        "# Step 5: Define your prompt\n",
        "prompt = (\n",
        "    \"An isometric exploded diagram of a lotus leaf, with photorealistic top surface, \"\n",
        "    \"wax nanorods below, stippled microstructure, and hemispherical domes in a grid. \"\n",
        "    \"Neutral grey background, no text, minimal line art, scientific style.\"\n",
        ")\n",
        "negative_prompt = \"blurry, distorted, shadows, artistic style, text, background scenery\"\n",
        "\n",
        "# Step 6: Generate base image with ControlNet + SDXL\n",
        "base_image = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=control_image,\n",
        "    num_inference_steps=20,\n",
        "    guidance_scale=8.0,\n",
        "    controlnet_conditioning_scale=1.0,\n",
        "    output_type=\"pil\",\n",
        "    denoising_end=0.8,  # Leave 20% for the refiner\n",
        ").images[0]\n",
        "\n",
        "# # Step 7: Refine the image using SDXL Refiner\n",
        "# refined_image = refiner(\n",
        "#     prompt=prompt,\n",
        "#     image=base_image,\n",
        "#     num_inference_steps=20,\n",
        "#     guidance_scale=5.0,\n",
        "#     denoising_start=0.8,\n",
        "# ).images[0]\n",
        "\n",
        "# Step 8: Save result\n",
        "base_image.save(\"refined_lotus_leaf_diagram.png\")\n"
      ],
      "metadata": {
        "id": "UAzQl2AinAWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_y_MFwenMW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cCZY-OG-nFfd"
      }
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRTZuOrabnCB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Adig1cwBbqdn"
      },
      "outputs": [],
      "source": [
        "# !pip install openai --quiet\n",
        "# !pip install fitz\n",
        "# !pip install pymupdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaRVJXicbs6V"
      },
      "source": [
        "## Imports & API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I6_PjVwbwui"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from peft import get_peft_model, LoraConfig\n",
        "import torch\n",
        "import base64\n",
        "import requests\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import display\n",
        "import fitz\n",
        "import fitz  # PyMuPDF\n",
        "import openai\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rW-qJh4bxQ2"
      },
      "outputs": [],
      "source": [
        "# get\n",
        "ai_token = userdata.get('ai_token')\n",
        "client = openai.OpenAI(api_key=ai_token)\n",
        "# print(ai_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NntHgjCb45t"
      },
      "outputs": [],
      "source": [
        "# # List all models\n",
        "# models = client.models.list()\n",
        "\n",
        "# # Print model IDs\n",
        "# for model in models.data:\n",
        "#     print(model.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a09Wy3bb6v4"
      },
      "source": [
        "## Load JSON File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENJIHbS0cEDR"
      },
      "outputs": [],
      "source": [
        "# Load your model description from JSON\n",
        "json_path = \"models_fibrillar interfaces.json\"  # change to your file\n",
        "with open(json_path, \"r\") as f:\n",
        "    model_data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAS7m45t0wV0"
      },
      "source": [
        "## Load PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iohoKiy6Vz85"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "import openai\n",
        "\n",
        "def extract_pdf_summary(pdf_path):\n",
        "    # === Step 1: Extract Text ===\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "\n",
        "    # === Step 3: Prompt GPT to extract core info ===\n",
        "    title_prompt = f\"\"\"\n",
        "    You are analyzing a scientific article. From the text below, extract:\n",
        "    1. A 4-6 words clean and accurate title that captures the paper’s topic\n",
        "    2. The final human-engineered object or system (e.g., \"Train\", \"Sensor\", \"Wing\", \"Nose Cone\", \"Surface Coating\")\n",
        "\n",
        "    Be concise. Output JSON like this:\n",
        "    {{\n",
        "      \"title\": \"...\",\n",
        "      \"organism_\": \"...\"\n",
        "    }}\n",
        "\n",
        "    Article:\n",
        "    \\\"\\\"\\\"\n",
        "    {text}\n",
        "    \\\"\\\"\\\"\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in summarizing scientific papers for visual infographic generation.\"},\n",
        "            {\"role\": \"user\", \"content\": title_prompt}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    answer = answer.strip().removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ZuO-l_JFV_1j",
        "outputId": "6ad81fa6-a741-42df-d3fb-16d7cfd334fe"
      },
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-207-3655294796.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fibrillar interfaces.pdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtitle_pdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_pdf_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-206-783417958.py\u001b[0m in \u001b[0;36mextract_pdf_summary\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "pdf_path = 'fibrillar interfaces.pdf'\n",
        "title_pdf = extract_pdf_summary(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_JZUyQobiC_"
      },
      "outputs": [],
      "source": [
        "title_pdf = json.loads(title_pdf)\n",
        "title_pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8ghbSWrcGb0"
      },
      "source": [
        "## Prompt to Generate Summary from JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "788MR8eLcLZi"
      },
      "outputs": [],
      "source": [
        "def generate_summary_prompt(model_data, filename=\"Untitled\"):\n",
        "\n",
        "    if isinstance(model_data, dict) and \"models\" in model_data:\n",
        "        models = model_data[\"models\"]\n",
        "        num = len(models)\n",
        "\n",
        "    if num > 1:\n",
        "      pdf = True\n",
        "      print(\"true\")\n",
        "      base_title = os.path.splitext(os.path.basename(filename))[0].replace(\"_\", \" \").title()\n",
        "      prompt = f\"\"\"\n",
        "You are given a JSON file that contains **multiple biological or technical models** under a key called \"models\".\n",
        "\n",
        "Each model has a `title`, an `organism`, and a list of `functional_components`.\n",
        "\n",
        "You should return a single structured JSON object summarizing **all models** as a multi-layer system.\n",
        "\n",
        "The output must include:\n",
        "- title: Use the filename as the global title (e.g., \"{base_title}\")\n",
        "- organism : object or organism based on the title\n",
        "- layers: Each model becomes a layer, derived from its first functional component.\n",
        "\n",
        "Each layer must include:\n",
        "  - name\n",
        "  - function: from the model's first functional component\n",
        "  - description\n",
        "  - caption: a condensed version of the function in ≤10 words\n",
        "  - scale: from the component\n",
        "  - visual: what to draw based on model + function\n",
        "\n",
        "Sort the layers by descending scale string (but do not convert units).\n",
        "\n",
        "Here is the data:\n",
        "{json.dumps(model_data, indent=2)}\n",
        "\"\"\"\n",
        "    elif num == 1:\n",
        "        pdf = False\n",
        "        print(\"False\")\n",
        "        prompt = f\"\"\"\n",
        "You are given the JSON below that describes a **single** biological or technical system.\n",
        "\n",
        "Extract a structured summary as a clean, valid JSON object with the following keys:\n",
        "- title\n",
        "- organism\n",
        "- layers: a list of objects sorted from largest to smallest based on the scale string (but do not convert the units), make sure it's sorted from the largest to the smallest\n",
        "\n",
        "Each layer should include:\n",
        "  - name\n",
        "  - function\n",
        "  - description\n",
        "  - caption (a condensed version of the function in ≤10 words)\n",
        "  - scale\n",
        "  - visual (a short instruction on what to draw)\n",
        "\n",
        "Here is the data:\n",
        "{json.dumps(model_data, indent=2)}\n",
        "\"\"\"\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV9NqF1P0eXr"
      },
      "outputs": [],
      "source": [
        "prompt = generate_summary_prompt(model_data,json_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L7LLvrpcO2y"
      },
      "source": [
        "## Call ChatGPT-4o to Summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYKFqke-cNC2"
      },
      "outputs": [],
      "source": [
        "#client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You extract and organize JSON content for scientific diagram generation.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "raw_output = response.choices[0].message.content\n",
        "\n",
        "# Remove the triple backticks and optional 'json'\n",
        "cleaned = raw_output.strip().removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
        "\n",
        "\n",
        "# Parse into Python dict\n",
        "data = json.loads(cleaned)\n",
        "if type(data) == list:\n",
        "  data = data[0]\n",
        "\n",
        "#summary = json.loads(response.choices[0].message.content)\n",
        "# print(data)\n",
        "\n",
        "\n",
        "print(json.dumps(data, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l60J82QmcRUL"
      },
      "source": [
        "## Generate Final Prompt for Image Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8bAGTCwcUUt"
      },
      "outputs": [],
      "source": [
        "def generate_infographic_prompt(summary, pdf= True):\n",
        "\n",
        "    title =  title_pdf['title'] if pdf else summary['title']\n",
        "    print(title_pdf['organism_'])\n",
        "\n",
        "    organism = title_pdf[\"organism_\"] if pdf else summary['organism']\n",
        "    layers = summary[\"layers\"]\n",
        "\n",
        "    prompt = f\"\"\"Create an isometric scientific infographic titled “{title}”, featuring vertically exploded layers aligned on a central axis, evenly spaced, and viewed from a 30° isometric camera angle on both X and Y axes.\n",
        "\n",
        "Layout & Visual Style:\n",
        "- Background: Flat grey (#CCCCCC) with a light isometric grid\n",
        "- No shadows, no icons, no decorative elements\n",
        "- Title: Bold, centered at the top: {title}\n",
        "\n",
        "Top Layer (Organism/System):\n",
        "- A photo-realistic rendering of the {organism}, viewed from above, centered.\n",
        "- No background environment—only the grid.\n",
        "\n",
        "Lower Layers (Functional Components, in black-and-white architectural line style):\"\"\"\n",
        "\n",
        "    for layer in layers:\n",
        "        prompt += f\"\"\"\n",
        "\n",
        "- “{layer['name']}”\n",
        "    - Left caption: “{layer['name']} – {layer['caption']}”\n",
        "    - Right label: {layer['scale']}\n",
        "    - Visual: {layer['visual']}\"\"\"\n",
        "\n",
        "    prompt += \"\"\"\n",
        "\n",
        "Final Visual Instructions:\n",
        "- Top layer: Full-color, photo-realistic\n",
        "- Lower layers: Black-and-white line drawings\n",
        "- Vertical black ruler on the right, aligned to scales\n",
        "- Captions and labels outside the visuals, no overlaps\n",
        "- Maintain blueprint-style visual consistency\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "final_prompt = generate_infographic_prompt(data, pdf = False)\n",
        "print(final_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWwqPf1EZkw7"
      },
      "outputs": [],
      "source": [
        "final_prompt_test = \"\"\"\n",
        "Create an isometric scientific infographic titled “Lotus Leaf Superhydrophobic Surface (Droplet Impalement-Resistant)” featuring a vertically exploded diagram with exactly five layers. The layout should be clean, blueprint-style, with no decorative elements, and viewed from a 30° isometric camera angle on both X and Y axes. All components must be aligned on a central vertical axis and spaced evenly.\n",
        "\n",
        "Layout & Style:\n",
        "* Canvas format: Portrait (e.g., 1024×1536 or taller)\n",
        "* Background: Flat neutral grey (#CCCCCC) with a subtle isometric grid\n",
        "* No shadows, icons, or decorative elements\n",
        "* Title: Bold black font, centered at the top\n",
        "* Captions: Aligned to the left of each layer\n",
        "* Scale labels: Aligned to the right of each layer\n",
        "* Style: Top layer photo-realistic; all lower layers black-and-white architectural line drawings\n",
        "\n",
        "Top Layer (Organism):\n",
        "* Visual: A photo-realistic rendering of a round Lotus Leaf (Nelumbo) seen from above with visible green veins and a large glossy water droplet centered on it (strong reflection highlight on droplet)\n",
        "* Label (right): “Lotus Leaf (Nelumbo)”\n",
        "\n",
        "Layer 1 – Papillae\n",
        "* Caption (left): “Papillae – Micro-bumps reduce contact”\n",
        "* Label (right): “1–5 µm”\n",
        "* Visual: A regular grid of dome-shaped micro-bumps, resembling bubble wrap\n",
        "\n",
        "Layer 2 – Air Layer\n",
        "* Caption (left): “Air Layer – Trapped gas reduces adhesion”\n",
        "* Label (right): “1–5 µm”\n",
        "* Visual: A flat grid plane with a centered water droplet cross-section and a visible gas layer underneath\n",
        "\n",
        "Layer 2 – Nanohairs\n",
        "* Caption (left): “Nanohairs – Texture enhances repellency”\n",
        "* Label (right): “200 nm”\n",
        "* Visual: A forest of vertical nano-needle hairs densely packed\n",
        "\n",
        "Layer 2 – Wax Crystals\n",
        "* Caption (left): “Wax Crystals – Low surface energy repels water”\n",
        "* Label (right): “100 nm”\n",
        "* Visual: A dense field of irregular, frost-like or grainy wax crystals\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjsnNFEVcWAa"
      },
      "source": [
        "## Generate Image via OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx-tXrj3cZcD"
      },
      "outputs": [],
      "source": [
        "result = client.images.generate(\n",
        "    model=\"gpt-image-1\",\n",
        "    prompt= final_prompt,\n",
        "    n=1,\n",
        "    size=\"1024x1536\"\n",
        ")\n",
        "\n",
        "image_base64 = result.data[0].b64_json\n",
        "image_bytes = base64.b64decode(image_base64)\n",
        "image = PILImage.open(BytesIO(image_bytes))\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5pJPyBHP_Kv"
      },
      "outputs": [],
      "source": [
        "# Save the image to a file\n",
        "# with open(\"otter.png\", \"wb\") as f:\n",
        "#     f.write(image_bytes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
